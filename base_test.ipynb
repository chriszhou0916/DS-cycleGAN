{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown args: ['-f', '/Users/chriszhou/Library/Jupyter/runtime/kernel-7ee0352a-b577-4bff-b09e-abc31037bc45.json']\n",
      "Parsed args: {'bs': 1, 'in_h': 256, 'in_w': 256, 'epochs': 40, 'm': True, 'is_test': False, 'cycle_consistency_loss': 10, 'job_dir': './trained_models/tmp1573968661.956428', 'model_dir': './trained_models/models', 'image_dir': './trained_models/images'}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from trainer.config import config\n",
    "from trainer.utils import dataset\n",
    "from trainer import utils\n",
    "from trainer.models import networks\n",
    "from trainer import models\n",
    "from trainer import callbacks\n",
    "\n",
    "LOG_DIR = config.job_dir\n",
    "MODEL_DIR = config.model_dir\n",
    "\n",
    "# Load Data (Build your custom data loader and replace below)\n",
    "train_horses, train_zebras, test_horses, test_zebras = dataset.generate_dataset()\n",
    "dataset_count = 1000\n",
    "# Select and Compile Model\n",
    "g_AB = networks.create_generator(shape=(config.in_h, config.in_w, 3))\n",
    "\n",
    "g_BA = networks.create_generator(shape=(config.in_h, config.in_w, 3))\n",
    "\n",
    "d_A = networks.create_discriminator(shape=(config.in_h, config.in_w, 3))\n",
    "\n",
    "d_B = networks.create_discriminator(shape=(config.in_h, config.in_w, 3))\n",
    "\n",
    "model = models.CycleGAN(shape = (None, None, 3),\n",
    "                        g_AB=g_AB,\n",
    "                        g_BA=g_BA,\n",
    "                        d_B=d_B,\n",
    "                        d_A=d_A)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),\n",
    "              d_loss='mse',\n",
    "              g_loss = [\n",
    "                 'mse', 'mse',\n",
    "                 'mae', 'mae',\n",
    "                 'mae', 'mae'\n",
    "              ], loss_weights = [\n",
    "                 1,  1,\n",
    "                 config.cycle_consistency_loss, config.cycle_consistency_loss,\n",
    "                 1,  1\n",
    "              ],\n",
    "              metrics=[utils.ssim, utils.psnr, utils.mae, utils.mse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, write_graph=True, update_freq='epoch')\n",
    "start_tensorboard = callbacks.StartTensorBoard(LOG_DIR)\n",
    "\n",
    "prog_bar = tf.keras.callbacks.ProgbarLogger(count_mode='steps', stateful_metrics=None)\n",
    "log_code = callbacks.LogCode(LOG_DIR, './trainer')\n",
    "copy_keras = callbacks.CopyKerasModel(MODEL_DIR, LOG_DIR)\n",
    "\n",
    "saving = callbacks.MultiModelCheckpoint(MODEL_DIR + '/model.{epoch:02d}-{val_ssim:.10f}.hdf5',\n",
    "                                        monitor='val_ssim', verbose=1, freq='epoch', mode='max', save_best_only=True,\n",
    "                                        multi_models=[('g_AB', g_AB), ('g_BA', g_BA), ('d_A', d_A), ('d_B', d_B)])\n",
    "\n",
    "reduce_lr = callbacks.MultiReduceLROnPlateau(training_models=[model.d_A, model.d_B, model.combined],\n",
    "                                             monitor='val_ssim', mode='max', factor=0.5, patience=3, min_lr=0.000002)\n",
    "# early_stopping = callbacks.MultiEarlyStopping(multi_models=[g_AB, g_BA, d_A, d_B], full_model=model,\n",
    "#                                               monitor='val_ssim', mode='max', patience=1,\n",
    "#                                               restore_best_weights=True, verbose=1)\n",
    "\n",
    "image_gen = callbacks.GenerateImages(g_AB, test_horses, test_zebras, LOG_DIR, interval=int(dataset_count/config.bs))\n",
    "\n",
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_horses:\n",
    "    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PrefetchDataset' object has no attribute 'get_next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-034f6e8ce511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_horses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'PrefetchDataset' object has no attribute 'get_next'"
     ]
    }
   ],
   "source": [
    "train_horses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
