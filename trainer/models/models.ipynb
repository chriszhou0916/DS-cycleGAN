{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from MyInstanceNorm import MyInstanceNorm\n",
    "\n",
    "class ReflectionPadding2D(tf.keras.layers.Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [tf.keras.layers.InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, s):\n",
    "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'padding':\n",
    "            self.padding\n",
    "        }\n",
    "        base_config = super(ReflectionPadding2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "def normalization(intput_tensor, method='instance'):\n",
    "  if method == 'instance':\n",
    "    x = MyInstanceNorm(center=True, scale=True,\n",
    "                                                  beta_initializer=\"random_uniform\",\n",
    "                                                  gamma_initializer=\"random_uniform\")(intput_tensor)\n",
    "  else:\n",
    "    x = tf.keras.layers.BatchNormalization()(intput_tensor)\n",
    "  return x\n",
    "\n",
    "def conv_w_reflection(input_tensor,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stride):\n",
    "  p = kernel_size // 2\n",
    "  x = ReflectionPadding2D(padding=(p, p))(input_tensor)\n",
    "  x = tf.keras.layers.Conv2D(filters, kernel_size, strides=stride, use_bias=False)(x)\n",
    "  x = normalization(x, method='instance')\n",
    "  x = tf.keras.layers.Activation(tf.nn.relu)(x)\n",
    "  return x\n",
    "\n",
    "def conv_block(input_tensor, filters):\n",
    "  x = ReflectionPadding2D(padding=(1, 1))(input_tensor)\n",
    "  x = tf.keras.layers.Conv2D(filters, kernel_size=3, strides=(1, 1), use_bias=False)(x)\n",
    "  x = normalization(x, method='instance')\n",
    "  x = tf.keras.layers.Activation(tf.nn.relu)(x)\n",
    "\n",
    "  x = ReflectionPadding2D(padding=(1, 1))(x)\n",
    "  x = tf.keras.layers.Conv2D(filters, kernel_size=3, strides=(1, 1), use_bias=False)(x)\n",
    "  x = normalization(x, method='instance')\n",
    "  return x\n",
    "\n",
    "def residual_block(input_tensor, filters):\n",
    "  b1 = conv_block(input_tensor, filters)\n",
    "  x = tf.keras.layers.Add()([input_tensor, b1])\n",
    "  return x\n",
    "\n",
    "def upsample_conv(input_tensor, kernel_size, filters, stride):\n",
    "  x = tf.keras.layers.Conv2DTranspose(filters, kernel_size, strides=stride, padding='same', use_bias=False)(input_tensor)\n",
    "  x = normalization(x, method='instance')\n",
    "  x = tf.keras.layers.Activation(tf.nn.relu)(x)\n",
    "  return x\n",
    "\n",
    "def create_generator(input_dim=3, output_dim=3):\n",
    "    inputs = tf.keras.layers.Input(shape=(256, 256, input_dim))\n",
    "    x = conv_w_reflection(inputs, 7, 64, 1)\n",
    "    x = conv_w_reflection(x, 3, 128, 2)\n",
    "    x = conv_w_reflection(x, 3, 256, 2)\n",
    "    x = residual_block(x, 256)\n",
    "    x = residual_block(x, 256)\n",
    "    x = residual_block(x, 256)\n",
    "    \n",
    "    x = residual_block(x, 256)\n",
    "    x = residual_block(x, 256)\n",
    "    x = residual_block(x, 256)\n",
    "    \n",
    "    x = residual_block(x, 256)\n",
    "    x = residual_block(x, 256)\n",
    "    x = residual_block(x, 256)\n",
    "    x = upsample_conv(x, 3, 128, 2)\n",
    "    x = upsample_conv(x, 3, 64, 2)\n",
    "    x = ReflectionPadding2D(padding=(3, 3))(x)\n",
    "    x = tf.keras.layers.Conv2D(3, 7, strides=1, activation='tanh')(x)\n",
    "#     x = tf.keras.layers.Conv2DTranspose(output_dim, kernel_size=7, strides=1, padding='same', activation='tanh')(x)\n",
    "# #     x = tf.keras.layers.Lambda(lambda x: tf.math.scalar_mul(255./2, x) + 255./2)(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "#     return x\n",
    "\n",
    "def dis_downsample(input_tensor,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stride, norm=True):\n",
    "  p = 1\n",
    "  x = ReflectionPadding2D(padding=(p, p))(input_tensor)\n",
    "  x = tf.keras.layers.Conv2D(filters, kernel_size, strides=stride)(x)\n",
    "  if norm:\n",
    "    x = normalization(x, method='instance')\n",
    "  x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "  return x\n",
    "\n",
    "def create_discriminator(input_dim=3, output_dim=3):\n",
    "    inputs = tf.keras.layers.Input(shape=(256, 256, input_dim))\n",
    "    x = dis_downsample(inputs, 4, 64, 2, norm=False)\n",
    "    x = dis_downsample(x, 4, 128, 2, norm=True)\n",
    "    x = dis_downsample(x, 4, 256, 2, norm=True)\n",
    "    x = dis_downsample(x, 4, 512, 1, norm=True)\n",
    "    x = tf.keras.layers.Conv2D(filters=1, kernel_size=4, strides=1, padding='same')(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "reflection_padding2d_236 (Re (None, 258, 258, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_240 (Conv2D)          (None, 128, 128, 64)      3136      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "reflection_padding2d_237 (Re (None, 130, 130, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_241 (Conv2D)          (None, 64, 64, 128)       131200    \n",
      "_________________________________________________________________\n",
      "my_instance_norm_234 (MyInst (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "reflection_padding2d_238 (Re (None, 66, 66, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_242 (Conv2D)          (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "my_instance_norm_235 (MyInst (None, 32, 32, 256)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "reflection_padding2d_239 (Re (None, 34, 34, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_243 (Conv2D)          (None, 31, 31, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "my_instance_norm_236 (MyInst (None, 31, 31, 512)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)   (None, 31, 31, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_244 (Conv2D)          (None, 31, 31, 1)         8193      \n",
      "=================================================================\n",
      "Total params: 2,766,529\n",
      "Trainable params: 2,766,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g = create_discriminator()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
